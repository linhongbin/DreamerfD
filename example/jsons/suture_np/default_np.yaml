action_repeat: 1
actor: {act: elu, dist: auto, layers: 4, min_std: 0.1, norm: none, units: 400}
actor_ent: 2e-03
actor_grad: auto
actor_grad_mix: 0.1
actor_grad_weight: 1.0
actor_opt: {clip: 100, eps: 1e-05, lr: 2e-05, opt: adam, wd: 1e-06}
actor_type: ActorCritic
atari_grayscale: true
bc_agent_retrain: true
bc_wm_retrain: true
bc_dir: ./data/suture/needle_picking/ambf/dream2suture/train_episodes/oracle
bc_grad_weight: 1.0
bc_loss: true
bc_skip_start_step_num: 2
clip_rewards: identity
critic: {act: elu, dist: mse, layers: 4, norm: none, units: 400}
critic_opt: {clip: 100, eps: 1e-05, lr: 4e-05, opt: adam, wd: 1e-06}
dataset: {batch: 70, length: 10}
decoder:
  act: elu
  cnn_depth: 48
  cnn_kernels: [5, 5, 6, 6]
  cnn_keys: image
  mlp_keys: $^
  mlp_layers: [400, 400, 400, 400]
  norm: none
disag_action_cond: true
disag_log: false
disag_models: 10
disag_offset: 1
disag_target: stoch
discount: 0.999
discount_head: {act: elu, dist: binary, layers: 4, norm: none, units: 400}
discount_lambda: 0.95
dmc_camera: -1
encoder:
  act: elu
  cnn_depth: 48
  cnn_kernels: [4, 4, 4, 4]
  cnn_keys: image
  mlp_keys: $^
  mlp_layers: [400, 400, 400, 400]
  norm: none
envs: 1
envs_parallel: none
eval_eps: 10
eval_every: 2000.0
eval_noise: 0.0
eval_state_mean: false
eval_success_reward: 0.99
eval_video_every: 2e4
expl_behavior: greedy
expl_extr_scale: 0.0
expl_head: {act: elu, dist: mse, layers: 4, norm: none, units: 400}
expl_intr_scale: 1.0
expl_model_loss: kl
expl_noise: 0.0
expl_opt: {clip: 100, eps: 1e-05, lr: 0.0003, opt: adam, wd: 1e-06}
expl_reward_norm: {eps: 1e-08, momentum: 1.0, scale: 1.0}
expl_until: 0
grad_extra_image_channel_scale: [0.0, 0.0, 0.0]
grad_heads: [decoder, reward, discount]
grad_uniform_image: true
imag_horizon: 15
is_pure_datagen: false
is_pure_train: false
jit: true
kl: {balance: 0.8, forward: false, free: 0.0, free_avg: true}
log_every: 400.0
log_keys_max: ^$
log_keys_mean: ^$
log_keys_sum: ^$
log_keys_video: [image]
logdir: ./data/suture/needle_picking/ambf/dream2suture
loss_scales: {discount: 1.0, kl: 1.0, proprio: 1.0, reward: 1.0}
model_opt: {clip: 100, eps: 1e-05, lr: 2e-4, opt: adam, wd: 1e-06}
offline_step: 20000000
precision: 16
pred_discount: true
prefill: 8000
prefill_agent: oracle
pretrain: 100
render_size: [64, 64]
replay: {capacity: 2000000.0, maxlen: 10, minlen: 10, ongoing: false, prioritize_ends: false}
reward_head: {act: elu, dist: mse, layers: 4, norm: none, units: 400}
reward_norm: {eps: 1e-08, momentum: 1.0, scale: 1.0}
reward_norm_skip: true
rssm: {act: elu, deter: 512, deter_quant: 0, discrete: 32, ensemble: 1, hidden: 512,
  min_std: 0.1, norm: none, std_act: sigmoid2, stoch: 32}
save_sucess_eps_filter_rate: 0.7
seed: 0
slow_baseline: true
slow_target: true
slow_target_fraction: 1
slow_target_update: 100
steps: 100000000.0
task: suture_ambf_np
time_limit: 100
train_carrystate: true
train_every: 50
train_mcts_batch_size: 16
train_mcts_c_puct: 5
train_mcts_gen_traj_every: 20
train_mcts_n_playout: 20
train_only_wm_steps: 0
train_seq_buffer: 1000
train_steps: 100
planner: {type: none}